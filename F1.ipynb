{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b044f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_try_n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ebb43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Krum_3-D0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "os.listdir('./try'+str(test_try_n)+'_result/')\n",
    "\n",
    "# ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbc73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_name=\"Krum_3-D0\"   #修改这里AVG-D0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2191238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_np(y0_score,y1_score):\n",
    "    p_num=len(y1_score)\n",
    "    n_num=len(y0_score)\n",
    "    x_label=np.array([0]*n_num+[1]*p_num)\n",
    "    x_score=np.array(y0_score+y1_score)\n",
    "    precision, recall, thresholds= metrics.precision_recall_curve(x_label, x_score, pos_label=1)\n",
    "    # 参考https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
    "    # thresholds是递增序列 precision和recall的长度比thresholds多1 precision的最后一个元素是1 recall的最后一个元素是0\n",
    "    \n",
    "    fenzi=2*recall*precision\n",
    "    fenmu=recall+precision\n",
    "    f1_scores=[(float(fenzi[i]/fenmu[i]) if fenmu[i]!=0 else -1.0) for i in range(len(fenzi))]\n",
    "    return precision, recall, thresholds, f1_scores\n",
    "\n",
    "def calculate_F1(y0_score,y1_score,threshold):\n",
    "    d={'TP':0,'FP':0,'FN':0,'TN':0}\n",
    "    for i in y0_score:\n",
    "        if i<threshold:\n",
    "            d['TN']+=1\n",
    "        else:\n",
    "            d['FP']+=1\n",
    "    for i in y1_score:\n",
    "        if i<threshold:\n",
    "            d['FN']+=1\n",
    "        else:\n",
    "            d['TP']+=1\n",
    "    Accuracy=(d['TP']+d['TN'])/(d['TP']+d['TN']+d['FP']+d['FN'])\n",
    "    Precision=d['TP']/(d['TP']+d['FP'])\n",
    "    Recall=d['TP']/(d['TP']+d['FN'])\n",
    "    F1=2*Precision*Recall/(Precision+Recall)\n",
    "    return Accuracy,Precision,Recall,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b906338a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold:  0.08968929946422577\n",
      "Best F1-Score:  0.9956082586770693\n",
      "DNS 0.9971412235563178 0.99408\n",
      "\n",
      "Best threshold:  0.2893509268760681\n",
      "Best F1-Score:  0.9993500844890164\n",
      "LDAP 0.9992202027472857 0.99948\n",
      "\n",
      "Best threshold:  0.16085591912269592\n",
      "Best F1-Score:  0.9992252285575755\n",
      "MSSQL 0.9989306309277526 0.99952\n",
      "\n",
      "Best threshold:  0.08987925946712494\n",
      "Best F1-Score:  0.9960805121864534\n",
      "NetBIOS 0.9972236421405017 0.99494\n",
      "\n",
      "Best threshold:  0.09140703082084656\n",
      "Best F1-Score:  0.9955160095992465\n",
      "NTP 0.9975200554222432 0.99352\n",
      "\n",
      "Best threshold:  0.08987553417682648\n",
      "Best F1-Score:  0.9963718979727667\n",
      "Portmap 0.9972252551863687 0.99552\n",
      "\n",
      "Best threshold:  0.08988220989704132\n",
      "Best F1-Score:  0.9981517004355993\n",
      "SNMP 0.997235087439112 0.99907\n",
      "\n",
      "Best threshold:  0.11369596421718597\n",
      "Best F1-Score:  0.998850333403313\n",
      "SSDP 0.9985608347158648 0.99914\n",
      "\n",
      "Best threshold:  0.07540317624807358\n",
      "Best F1-Score:  0.8894576918778836\n",
      "Syn 0.9505681365802614 0.83573\n",
      "\n",
      "Best threshold:  0.20259599387645721\n",
      "Best F1-Score:  0.9954133964953131\n",
      "TFTP 0.9990430718401225 0.99181\n",
      "\n",
      "Best threshold:  0.07602185010910034\n",
      "Best F1-Score:  0.9283473238031915\n",
      "UDPLag 0.9659179349705984 0.89359\n",
      "\n",
      "Best threshold:  0.1307588815689087\n",
      "Best F1-Score:  0.9987750551225194\n",
      "UDP 0.9987301142897139 0.99882\n",
      "\n",
      "Best threshold:  0.07553797215223312\n",
      "Best F1-Score:  0.9866085575445699\n",
      "[overall] 0.996582269118251 0.9768325\n"
     ]
    }
   ],
   "source": [
    "load_j = json.load(open(\"./try\"+str(test_try_n)+\"_result/\"+e_name+\"/score.json\", 'r'))\n",
    "\n",
    "for test_type in ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']:\n",
    "    precision, recall, thresholds, f1_scores=get_f1_np(load_j['BENIGN'],load_j[test_type])\n",
    "    \n",
    "    m_index=np.argmax(f1_scores)\n",
    "    print('Best threshold: ', thresholds[m_index])\n",
    "    print('Best F1-Score: ', np.max(f1_scores))\n",
    "    print(test_type,precision[m_index], recall[m_index])\n",
    "    print('')\n",
    "\n",
    "y1_score=[]\n",
    "for test_type in ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']:\n",
    "    y1_score=y1_score+load_j[test_type]\n",
    "precision, recall, thresholds, f1_scores=get_f1_np(load_j['BENIGN'],y1_score)\n",
    "\n",
    "m_index=np.argmax(f1_scores)\n",
    "print('Best threshold: ', thresholds[m_index])\n",
    "print('Best F1-Score: ', np.max(f1_scores))\n",
    "print('[overall]',precision[m_index], recall[m_index])\n",
    "\n",
    "Best_th=float(thresholds[m_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807be45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4acd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad29d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d3d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2afeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f37843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabTransformNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TabTransformNet, self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            # nn.Linear(79, 64,bias=False),\n",
    "            nn.Linear(66, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 66),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "\n",
    "class NeuTraL(nn.Module):\n",
    "    def __init__(self, num_trans):\n",
    "        super(NeuTraL, self).__init__()\n",
    "        self.enc=nn.Sequential(\n",
    "            nn.Linear(66, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "        )\n",
    "        self.num_trans=num_trans\n",
    "        self.trans = nn.ModuleList([TabTransformNet() for _ in range(self.num_trans)])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_T = torch.zeros(x.shape[0],self.num_trans,x.shape[-1]).to(x)\n",
    "        for i in range(self.num_trans):\n",
    "            mask = self.trans[i](x)\n",
    "            mask = torch.sigmoid(mask)\n",
    "            x_T[:, i] = mask * x\n",
    "        x_cat = torch.cat([x.unsqueeze(1),x_T],1)  # x_cat形状为[batch_size,self.num_trans+1,79]\n",
    "        zs = self.enc(x_cat.reshape(-1,x.shape[-1]))\n",
    "        z_dim=zs.shape[-1]\n",
    "        return zs.reshape(x.shape[0],self.num_trans+1,z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91324a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuTraL_loss(z,device,y,temp=0.1):\n",
    "    z=z.to(device)\n",
    "    z = nn.functional.normalize(z, p=2, dim=-1)\n",
    "    # 上面这一行 z本来形状为[batch_size,num_trans+1,z_dim] 处理后 每个z[a,b,:]向量都分别被变为长度为1\n",
    "    \n",
    "    z_ori = z[:, 0]  # n,z\n",
    "    z_trans = z[:, 1:]  # n,k-1, z\n",
    "    batch_size, num_trans, z_dim = z.shape  # 此处的num_trans实际上是num_trans+1\n",
    "\n",
    "    sim_matrix = torch.exp(torch.matmul(z, z.permute(0, 2, 1) / temp))  # n,k,k\n",
    "    \n",
    "    # 下面这一行 减号前的一项形状为[batch_size,num_trans+1,z_dim] 减号后的一项形状为[1,num_trans+1,z_dim]\n",
    "    # torch.eye()对角矩阵\n",
    "    mask = (torch.ones_like(sim_matrix).to(device) - torch.eye(num_trans).unsqueeze(0).to(device)).bool()\n",
    "    # 下面这一行 masked_select返回一维tensor\n",
    "    sim_matrix = sim_matrix.masked_select(mask).view(batch_size, num_trans, -1)\n",
    "    trans_matrix = sim_matrix[:, 1:].sum(-1)  # n,k-1\n",
    "\n",
    "    pos_sim = torch.exp(torch.sum(z_trans * z_ori.unsqueeze(1), -1) / temp) # n,k-1\n",
    "    K = num_trans - 1\n",
    "    scale = 1 / abs(K*float(torch.log(torch.tensor(1.0 / K))))\n",
    "\n",
    "    # loss_tensor = (torch.log(trans_matrix+1e-7) - torch.log(pos_sim+1e-7)) * scale\n",
    "    p_k=pos_sim/(trans_matrix+1e-7) # n,k-1\n",
    "    # y原本的形状是[n]\n",
    "    y=y.view(-1,1)\n",
    "    p_k_y=(1-y)*p_k+y*(1-p_k)\n",
    "    l_tensor =-torch.log(p_k_y+1e-7)\n",
    "    return l_tensor.sum(1)\n",
    "\n",
    "def e_loss(x,net,device):\n",
    "    # 测试时 仅使用损失函数的一项 需要传输全为0的y作为参数\n",
    "    y=torch.zeros(x.shape[0]).float()\n",
    "    y=y.to(device)\n",
    "    net = net.to(device)\n",
    "    x=x.to(device)\n",
    "    with torch.no_grad():\n",
    "        z=net(x)\n",
    "        l=NeuTraL_loss(z,device,y)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214ec4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riven\\AppData\\Local\\Temp\\ipykernel_30964\\4051924339.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./try'+str(test_try_n)+'_result/'+e_name+'/model.pt'))\n"
     ]
    }
   ],
   "source": [
    "t_num=4\n",
    "model = NeuTraL(t_num)\n",
    "model.load_state_dict(torch.load('./try'+str(test_try_n)+'_result/'+e_name+'/model.pt'))\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f8c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37574e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1fcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b336e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riven\\AppData\\Local\\Temp\\ipykernel_30964\\3692134789.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  v_x_0=torch.load('./F1/validition/validition_x.pt')\n",
      "C:\\Users\\riven\\AppData\\Local\\Temp\\ipykernel_30964\\3692134789.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  v_x_1=torch.cat((v_x_1,torch.load('./F1/validition/validition_'+i+'.pt')),dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([328, 66]) torch.Size([336, 66])\n"
     ]
    }
   ],
   "source": [
    "v_x_0=torch.load('./F1/validition/validition_x.pt')\n",
    "v_x_1=torch.zeros(0,66).float()\n",
    "for i in ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']:\n",
    "    v_x_1=torch.cat((v_x_1,torch.load('./F1/validition/validition_'+i+'.pt')),dim=0)\n",
    "print(v_x_0.shape,v_x_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd02c4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07603519409894943, 0.07553797215223312)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_score=e_loss(v_x_0,model,device).cpu().numpy().tolist()\n",
    "y1_score=e_loss(v_x_1,model,device).cpu().numpy().tolist()\n",
    "precision, recall, thresholds, f1_scores=get_f1_np(y0_score,y1_score)\n",
    "th_3=float(thresholds[np.argmax(f1_scores)])\n",
    "th_3,Best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2c5277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS\n",
      "threshold 0.07604,Accuracy 0.97727, Precision 0.96956, Recall 0.99948, F1 0.98429\n",
      "threshold 0.07554,Accuracy 0.97103, Precision 0.96134, Recall 0.99955, F1 0.98007\n",
      "LDAP\n",
      "threshold 0.07604,Accuracy 0.97747, Precision 0.96957, Recall 0.99977, F1 0.98444\n",
      "threshold 0.07554,Accuracy 0.97123, Precision 0.96135, Recall 0.99983, F1 0.98021\n",
      "MSSQL\n",
      "threshold 0.07604,Accuracy 0.97747, Precision 0.96957, Recall 0.99977, F1 0.98444\n",
      "threshold 0.07554,Accuracy 0.97122, Precision 0.96135, Recall 0.99981, F1 0.98020\n",
      "NetBIOS\n",
      "threshold 0.07604,Accuracy 0.97745, Precision 0.96957, Recall 0.99973, F1 0.98442\n",
      "threshold 0.07554,Accuracy 0.97117, Precision 0.96134, Recall 0.99975, F1 0.98017\n",
      "NTP\n",
      "threshold 0.07604,Accuracy 0.97618, Precision 0.96951, Recall 0.99796, F1 0.98353\n",
      "threshold 0.07554,Accuracy 0.96992, Precision 0.96128, Recall 0.99799, F1 0.97929\n",
      "Portmap\n",
      "threshold 0.07604,Accuracy 0.97732, Precision 0.96956, Recall 0.99955, F1 0.98433\n",
      "threshold 0.07554,Accuracy 0.97104, Precision 0.96134, Recall 0.99956, F1 0.98008\n",
      "SNMP\n",
      "threshold 0.07604,Accuracy 0.97740, Precision 0.96957, Recall 0.99967, F1 0.98439\n",
      "threshold 0.07554,Accuracy 0.97115, Precision 0.96134, Recall 0.99971, F1 0.98015\n",
      "SSDP\n",
      "threshold 0.07604,Accuracy 0.97745, Precision 0.96957, Recall 0.99973, F1 0.98442\n",
      "threshold 0.07554,Accuracy 0.97117, Precision 0.96134, Recall 0.99974, F1 0.98017\n",
      "Syn\n",
      "threshold 0.07604,Accuracy 0.84910, Precision 0.96313, Recall 0.81963, F1 0.88560\n",
      "threshold 0.07554,Accuracy 0.85233, Precision 0.95396, Recall 0.83298, F1 0.88938\n",
      "TFTP\n",
      "threshold 0.07604,Accuracy 0.97687, Precision 0.96954, Recall 0.99892, F1 0.98401\n",
      "threshold 0.07554,Accuracy 0.97061, Precision 0.96131, Recall 0.99896, F1 0.97978\n",
      "UDPLag\n",
      "threshold 0.07604,Accuracy 0.90162, Precision 0.96607, Recall 0.89333, F1 0.92827\n",
      "threshold 0.07554,Accuracy 0.89620, Precision 0.95699, Recall 0.89454, F1 0.92471\n",
      "UDP\n",
      "threshold 0.07604,Accuracy 0.97730, Precision 0.96956, Recall 0.99953, F1 0.98432\n",
      "threshold 0.07554,Accuracy 0.97105, Precision 0.96134, Recall 0.99957, F1 0.98008\n",
      "[overall]\n",
      "threshold 0.07604,Accuracy 0.97385, Precision 0.99733, Recall 0.97559, F1 0.98634\n",
      "threshold 0.07554,Accuracy 0.97434, Precision 0.99658, Recall 0.97683, F1 0.98661\n"
     ]
    }
   ],
   "source": [
    "for test_type in ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']:\n",
    "    print(test_type)\n",
    "    print('threshold %.5f' % (th_3),end=',')\n",
    "    print('Accuracy %.5f, Precision %.5f, Recall %.5f, F1 %.5f' % calculate_F1(load_j['BENIGN'],load_j[test_type],th_3))\n",
    "    \n",
    "    print('threshold %.5f' % (Best_th),end=',')\n",
    "    print('Accuracy %.5f, Precision %.5f, Recall %.5f, F1 %.5f' % calculate_F1(load_j['BENIGN'],load_j[test_type],Best_th))\n",
    "\n",
    "y1_score=[]\n",
    "for test_type in ['DNS', 'LDAP', 'MSSQL', 'NetBIOS', 'NTP', 'Portmap', 'SNMP', 'SSDP', 'Syn', 'TFTP', 'UDPLag', 'UDP']:\n",
    "    y1_score=y1_score+load_j[test_type]\n",
    "\n",
    "print('[overall]')\n",
    "print('threshold %.5f' % (th_3),end=',')\n",
    "print('Accuracy %.5f, Precision %.5f, Recall %.5f, F1 %.5f' % calculate_F1(load_j['BENIGN'],y1_score,th_3))\n",
    "\n",
    "print('threshold %.5f' % (Best_th),end=',')\n",
    "print('Accuracy %.5f, Precision %.5f, Recall %.5f, F1 %.5f' % calculate_F1(load_j['BENIGN'],y1_score,Best_th))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf9a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tup=calculate_F1(load_j['BENIGN'],y1_score,th_3)\n",
    "with open(\"./try\"+str(test_try_n)+\"_result/\"+e_name+\"/th.txt\", 'w') as f:\n",
    "    f.write('threshold\\tAccuracy\\tPrecision\\tRecall\\tF1\\n')\n",
    "    f.write(str(th_3))\n",
    "    f.write('\\t')\n",
    "    f.write(str(tup[0]))\n",
    "    f.write('\\t')\n",
    "    f.write(str(tup[1]))\n",
    "    f.write('\\t')\n",
    "    f.write(str(tup[2]))\n",
    "    f.write('\\t')\n",
    "    f.write(str(tup[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d84b390a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c23705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
